{"ast":null,"code":"'use strict';\n\nvar __extends = this && this.__extends || function () {\n  var _extendStatics = function extendStatics(d, b) {\n    _extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) {\n        if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];\n      }\n    };\n\n    return _extendStatics(d, b);\n  };\n\n  return function (d, b) {\n    if (typeof b !== \"function\" && b !== null) throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n\n    _extendStatics(d, b);\n\n    function __() {\n      this.constructor = d;\n    }\n\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\n\nvar MediaTrack = require('./mediatrack');\n\nvar VideoProcessorEventObserver = require('./videoprocessoreventobserver');\n\nvar DEFAULT_FRAME_RATE = require('../../util/constants').DEFAULT_FRAME_RATE;\n/**\n * A {@link VideoTrack} is a {@link Track} representing video.\n * @extends Track\n * @property {boolean} isStarted - Whether or not the {@link VideoTrack} has\n *   started; if the {@link VideoTrack} started, there is enough video data to\n *   begin playback\n * @property {boolean} isEnabled - Whether or not the {@link VideoTrack} is\n *   enabled; if the {@link VideoTrack} is not enabled, it is \"paused\"\n * @property {VideoTrack.Dimensions} dimensions - The {@link VideoTrack}'s\n *   {@link VideoTrack.Dimensions}\n * @property {Track.Kind} kind - \"video\"\n * @property {MediaStreamTrack} mediaStreamTrack - A video MediaStreamTrack\n * @property {?MediaStreamTrack} processedTrack - The source of processed video frames.\n * It is null if no VideoProcessor has been added.\n * @property {?VideoProcessor} processor - A {@link VideoProcessor} that is currently\n *   processing video frames. It is null if video frames are not being processed.\n * @emits VideoTrack#dimensionsChanged\n * @emits VideoTrack#disabled\n * @emits VideoTrack#enabled\n * @emits VideoTrack#started\n */\n\n\nvar VideoTrack =\n/** @class */\nfunction (_super) {\n  __extends(VideoTrack, _super);\n  /**\n   * Construct a {@link VideoTrack}.\n   * @param {MediaTrackTransceiver} mediaTrackTransceiver\n   * @param {{log: Log}} options\n   */\n\n\n  function VideoTrack(mediaTrackTransceiver, options) {\n    var _this = _super.call(this, mediaTrackTransceiver, options) || this;\n\n    Object.defineProperties(_this, {\n      _captureTimeoutId: {\n        value: null,\n        writable: true\n      },\n      _isCapturing: {\n        value: false,\n        writable: true\n      },\n      _inputFrame: {\n        value: null,\n        writable: true\n      },\n      _outputFrame: {\n        value: null,\n        writable: true\n      },\n      _processorEventObserver: {\n        value: null,\n        writable: true\n      },\n      _unmuteHandler: {\n        value: null,\n        writable: true\n      },\n      dimensions: {\n        enumerable: true,\n        value: {\n          width: null,\n          height: null\n        }\n      },\n      processor: {\n        enumerable: true,\n        value: null,\n        writable: true\n      }\n    });\n    _this._processorEventObserver = new (options.VideoProcessorEventObserver || VideoProcessorEventObserver)(_this._log);\n    return _this;\n  }\n  /**\n   * @private\n   */\n\n\n  VideoTrack.prototype._checkIfCanCaptureFrames = function (isPublishing) {\n    if (isPublishing === void 0) {\n      isPublishing = false;\n    }\n\n    var canCaptureFrames = true;\n    var message = '';\n    var _a = this.mediaStreamTrack,\n        enabled = _a.enabled,\n        readyState = _a.readyState;\n\n    if (!enabled) {\n      canCaptureFrames = false;\n      message = 'MediaStreamTrack is disabled';\n    }\n\n    if (readyState === 'ended') {\n      canCaptureFrames = false;\n      message = 'MediaStreamTrack is ended';\n    }\n\n    if (!this.processor) {\n      canCaptureFrames = false;\n      message = 'VideoProcessor not detected.';\n    }\n\n    if (!this._attachments.size && !isPublishing) {\n      canCaptureFrames = false;\n      message = 'VideoTrack is not publishing and there is no attached element.';\n    }\n\n    if (message) {\n      this._log.debug(message);\n    }\n\n    return {\n      canCaptureFrames: canCaptureFrames,\n      message: message\n    };\n  };\n  /**\n   * @private\n   */\n\n\n  VideoTrack.prototype._captureFrames = function () {\n    var _this = this;\n\n    if (this._isCapturing) {\n      this._log.debug('Ignoring captureFrames call. Capture is already in progress');\n\n      return;\n    }\n\n    if (!this._checkIfCanCaptureFrames().canCaptureFrames) {\n      this._isCapturing = false;\n\n      this._log.debug('Cannot capture frames. Ignoring captureFrames call.');\n\n      return;\n    }\n\n    this._isCapturing = true;\n\n    this._processorEventObserver.emit('start');\n\n    this._log.debug('Start capturing frames');\n\n    var startTime = Date.now();\n    var processFramePeriodMs;\n\n    this._dummyEl.play().then(function () {\n      var captureFrame = function captureFrame(cb) {\n        clearTimeout(_this._captureTimeoutId);\n\n        var _a = _this.mediaStreamTrack.getSettings().frameRate,\n            frameRate = _a === void 0 ? DEFAULT_FRAME_RATE : _a;\n\n        var capturePeriodMs = Math.floor(1000 / frameRate);\n        var delay = capturePeriodMs - processFramePeriodMs;\n\n        if (delay < 0 || typeof processFramePeriodMs !== 'number') {\n          delay = 0;\n        }\n\n        _this._captureTimeoutId = setTimeout(cb, delay);\n      };\n\n      var process = function process() {\n        var checkResult = _this._checkIfCanCaptureFrames();\n\n        if (!checkResult.canCaptureFrames) {\n          _this._isCapturing = false;\n\n          _this._processorEventObserver.emit('stop', checkResult.message);\n\n          _this._log.debug('Cannot capture frames. Stopping capturing frames.');\n\n          return;\n        }\n\n        startTime = Date.now();\n\n        var _a = _this.mediaStreamTrack.getSettings(),\n            _b = _a.width,\n            width = _b === void 0 ? 0 : _b,\n            _c = _a.height,\n            height = _c === void 0 ? 0 : _c; // Setting the canvas' dimension triggers a redraw.\n        // Only set it if it has changed.\n\n\n        if (_this._inputFrame.width !== width) {\n          _this._inputFrame.width = width;\n          _this._inputFrame.height = height;\n\n          if (_this._outputFrame) {\n            _this._outputFrame.width = width;\n            _this._outputFrame.height = height;\n          }\n        }\n\n        _this._inputFrame.getContext('2d').drawImage(_this._dummyEl, 0, 0, width, height);\n\n        var result = null;\n\n        try {\n          result = _this.processor.processFrame(_this._inputFrame, _this._outputFrame);\n        } catch (ex) {\n          _this._log.debug('Exception detected after calling processFrame.', ex);\n        }\n\n        (result instanceof Promise ? result : Promise.resolve(result)).then(function () {\n          if (_this._outputFrame) {\n            _this.processedTrack.requestFrame();\n\n            _this._processorEventObserver.emit('stats');\n          }\n        }).finally(function () {\n          processFramePeriodMs = Date.now() - startTime;\n          captureFrame(process);\n        });\n      };\n\n      captureFrame(process);\n    }).catch(function (error) {\n      return _this._log.error('Video element cannot be played', {\n        error: error,\n        track: _this\n      });\n    });\n  };\n  /**\n   * @private\n   */\n\n\n  VideoTrack.prototype._initialize = function () {\n    var _this = this;\n\n    _super.prototype._initialize.call(this);\n\n    if (this._dummyEl) {\n      this._dummyEl.onloadedmetadata = function () {\n        if (dimensionsChanged(_this, _this._dummyEl)) {\n          _this.dimensions.width = _this._dummyEl.videoWidth;\n          _this.dimensions.height = _this._dummyEl.videoHeight;\n        }\n      };\n\n      this._dummyEl.onresize = function () {\n        if (dimensionsChanged(_this, _this._dummyEl)) {\n          _this.dimensions.width = _this._dummyEl.videoWidth;\n          _this.dimensions.height = _this._dummyEl.videoHeight;\n\n          if (_this.isStarted) {\n            _this._log.debug('Dimensions changed:', _this.dimensions);\n\n            _this.emit(VideoTrack.DIMENSIONS_CHANGED, _this);\n          }\n        }\n      };\n    }\n  };\n  /**\n   * @private\n   */\n\n\n  VideoTrack.prototype._restartProcessor = function () {\n    var processor = this.processor;\n\n    if (processor) {\n      this.removeProcessor(processor);\n      this.addProcessor(processor);\n    }\n  };\n  /**\n   * @private\n   */\n\n\n  VideoTrack.prototype._start = function (dummyEl) {\n    this.dimensions.width = dummyEl.videoWidth;\n    this.dimensions.height = dummyEl.videoHeight;\n\n    this._log.debug('Dimensions:', this.dimensions);\n\n    this.emit(VideoTrack.DIMENSIONS_CHANGED, this);\n    return _super.prototype._start.call(this, dummyEl);\n  };\n  /**\n   * Add a {@link VideoProcessor} to allow for custom processing of video frames belonging to a VideoTrack.\n   * Only Chrome supports this as of now. Calling this API from a non-supported browser will result in a log warning.\n   * @param {VideoProcessor} processor - The {@link VideoProcessor} to use.\n   * @returns {this}\n   * @example\n   * class GrayScaleProcessor {\n   *   constructor(percentage) {\n   *     this.percentage = percentage;\n   *   }\n   *   processFrame(inputFrameBuffer, outputFrameBuffer) {\n   *     const context = outputFrameBuffer.getContext('2d');\n   *     context.filter = `grayscale(${this.percentage}%)`;\n   *     context.drawImage(inputFrameBuffer, 0, 0, inputFrameBuffer.width, inputFrameBuffer.height);\n   *   }\n   * }\n   *\n   * Video.createLocalVideoTrack().then(function(videoTrack) {\n   *   videoTrack.addProcessor(new GrayScaleProcessor(100));\n   * });\n   */\n\n\n  VideoTrack.prototype.addProcessor = function (processor) {\n    var _this = this;\n\n    if (typeof OffscreenCanvas !== 'function') {\n      return this._log.warn('Adding a VideoProcessor is not supported in this browser.');\n    }\n\n    if (!processor || typeof processor.processFrame !== 'function') {\n      throw new Error('Received an invalid VideoProcessor from addProcessor.');\n    }\n\n    if (this.processor) {\n      throw new Error('A VideoProcessor has already been added.');\n    }\n\n    if (!this._dummyEl) {\n      throw new Error('VideoTrack has not been initialized.');\n    }\n\n    this._log.debug('Adding VideoProcessor to the VideoTrack', processor);\n\n    if (!this._unmuteHandler) {\n      this._unmuteHandler = function () {\n        _this._log.debug('mediaStreamTrack unmuted'); // NOTE(csantos): On certain scenarios where mediaStreamTrack is coming from muted to unmuted state,\n        // the processedTrack doesn't unmutes automatically although enabled is already set to true.\n        // This is a terminal state for the processedTrack and should be restarted. (VIDEO-4176)\n\n\n        if (_this.processedTrack.muted) {\n          _this._log.debug('mediaStreamTrack is unmuted but processedTrack is muted. Restarting processor.');\n\n          _this._restartProcessor();\n        }\n      };\n\n      this.mediaStreamTrack.addEventListener('unmute', this._unmuteHandler);\n    }\n\n    var _a = this.mediaStreamTrack.getSettings(),\n        _b = _a.width,\n        width = _b === void 0 ? 0 : _b,\n        _c = _a.height,\n        height = _c === void 0 ? 0 : _c,\n        _d = _a.frameRate,\n        frameRate = _d === void 0 ? DEFAULT_FRAME_RATE : _d;\n\n    this._inputFrame = new OffscreenCanvas(width, height);\n    this._outputFrame = document.createElement('canvas');\n    this._outputFrame.width = width;\n    this._outputFrame.height = height;\n    this.processedTrack = this._outputFrame.captureStream(0).getTracks()[0];\n    this.processedTrack.enabled = this.mediaStreamTrack.enabled;\n    this.processor = processor;\n\n    this._processorEventObserver.emit('add', {\n      processor: processor,\n      captureHeight: height,\n      captureWidth: width,\n      inputFrameRate: frameRate,\n      isRemoteVideoTrack: this.toString().includes('RemoteVideoTrack')\n    });\n\n    this._updateElementsMediaStreamTrack();\n\n    this._captureFrames();\n\n    return this;\n  };\n  /**\n   * Create an HTMLVideoElement and attach the {@link VideoTrack} to it.\n   *\n   * The HTMLVideoElement's <code>srcObject</code> will be set to a new\n   * MediaStream containing the {@link VideoTrack}'s MediaStreamTrack.\n   *\n   * @returns {HTMLVideoElement} videoElement\n   * @example\n   * const Video = require('twilio-video');\n   *\n   * Video.createLocalVideoTrack().then(function(videoTrack) {\n   *   const videoElement = videoTrack.attach();\n   *   document.body.appendChild(videoElement);\n   * });\n  */\n\n  /**\n  * Attach the {@link VideoTrack} to an existing HTMLMediaElement. The\n  * HTMLMediaElement could be an HTMLAudioElement or an HTMLVideoElement.\n  *\n  * If the HTMLMediaElement's <code>srcObject</code> is not set to a MediaStream,\n  * this method sets it to a new MediaStream containing the {@link VideoTrack}'s\n  * MediaStreamTrack; otherwise, it adds the {@link MediaTrack}'s\n  * MediaStreamTrack to the existing MediaStream. Finally, if there are any other\n  * MediaStreamTracks of the same kind on the MediaStream, this method removes\n  * them.\n  *\n  * @param {HTMLMediaElement} mediaElement - The HTMLMediaElement to attach to\n  * @returns {HTMLMediaElement} mediaElement\n  * @example\n  * const Video = require('twilio-video');\n  *\n  * const videoElement = document.createElement('video');\n  * document.body.appendChild(videoElement);\n  *\n  * Video.createLocalVideoTrack().then(function(videoTrack) {\n  *   videoTrack.attach(videoElement);\n  * });\n  */\n\n  /**\n  * Attach the {@link VideoTrack} to an HTMLMediaElement selected by\n  * <code>document.querySelector</code>. The HTMLMediaElement could be an\n  * HTMLAudioElement or an HTMLVideoElement.\n  *\n  * If the HTMLMediaElement's <code>srcObject</code> is not set to a MediaStream,\n  * this method sets it to a new MediaStream containing the {@link VideoTrack}'s\n  * MediaStreamTrack; otherwise, it adds the {@link VideoTrack}'s\n  * MediaStreamTrack to the existing MediaStream. Finally, if there are any other\n  * MediaStreamTracks of the same kind on the MediaStream, this method removes\n  * them.\n  *\n  * @param {string} selector - A query selector for the HTMLMediaElement to\n  *   attach to\n  * @returns {HTMLMediaElement} mediaElement\n  * @example\n  * const Video = require('twilio-video');\n  *\n  * const videoElement = document.createElement('video');\n  * videoElement.id = 'my-video-element';\n  * document.body.appendChild(videoElement);\n  *\n  * Video.createLocalVideoTrack().then(function(track) {\n  *   track.attach('#my-video-element');\n  * });\n  */\n\n\n  VideoTrack.prototype.attach = function () {\n    var result = _super.prototype.attach.apply(this, arguments);\n\n    if (this.processor) {\n      this._captureFrames();\n    }\n\n    return result;\n  };\n  /**\n   * Detach the {@link VideoTrack} from all previously attached HTMLMediaElements.\n   * @returns {Array<HTMLMediaElement>} mediaElements\n   * @example\n   * const mediaElements = videoTrack.detach();\n   * mediaElements.forEach(mediaElement => mediaElement.remove());\n  */\n\n  /**\n  * Detach the {@link VideoTrack} from a previously attached HTMLMediaElement.\n  * @param {HTMLMediaElement} mediaElement - One of the HTMLMediaElements to\n  *   which the {@link VideoTrack} is attached\n  * @returns {HTMLMediaElement} mediaElement\n  * @example\n  * const videoElement = document.getElementById('my-video-element');\n  * videoTrack.detach(videoElement).remove();\n  */\n\n  /**\n  * Detach the {@link VideoTrack} from a previously attached HTMLMediaElement\n  *   specified by <code>document.querySelector</code>.\n  * @param {string} selector - The query selector of HTMLMediaElement to which\n  *    the {@link VideoTrack} is attached\n  * @returns {HTMLMediaElement} mediaElement\n  * @example\n  * videoTrack.detach('#my-video-element').remove();\n  */\n\n\n  VideoTrack.prototype.detach = function () {\n    return _super.prototype.detach.apply(this, arguments);\n  };\n  /**\n   * Remove the previously added {@link VideoProcessor} using `addProcessor` API.\n   * @param {VideoProcessor} processor - The {@link VideoProcessor} to remove.\n   * @returns {this}\n   * @example\n   * class GrayScaleProcessor {\n   *   constructor(percentage) {\n   *     this.percentage = percentage;\n   *   }\n   *   processFrame(inputFrameBuffer, outputFrameBuffer) {\n   *     const context = outputFrameBuffer.getContext('2d');\n   *     context.filter = `grayscale(${this.percentage}%)`;\n   *     context.drawImage(inputFrameBuffer, 0, 0, inputFrameBuffer.width, inputFrameBuffer.height);\n   *   }\n   * }\n   *\n   * Video.createLocalVideoTrack().then(function(videoTrack) {\n   *   const grayScaleProcessor = new GrayScaleProcessor(100);\n   *   videoTrack.addProcessor(grayScaleProcessor);\n   *   document.getElementById('remove-button').onclick = () => videoTrack.removeProcessor(grayScaleProcessor);\n   * });\n   */\n\n\n  VideoTrack.prototype.removeProcessor = function (processor) {\n    if (!processor) {\n      throw new Error('Received an invalid VideoProcessor from removeProcessor.');\n    }\n\n    if (!this.processor) {\n      throw new Error('No existing VideoProcessor detected.');\n    }\n\n    if (processor !== this.processor) {\n      throw new Error('The provided VideoProcessor is different than the existing one.');\n    }\n\n    this._processorEventObserver.emit('remove');\n\n    this._log.debug('Removing VideoProcessor from the VideoTrack', processor);\n\n    clearTimeout(this._captureTimeoutId);\n    this.mediaStreamTrack.removeEventListener('unmute', this._unmuteHandler);\n    this._unmuteHandler = null;\n    this._isCapturing = false;\n    this.processor = null;\n    this.processedTrack = null;\n\n    this._inputFrame.getContext('2d').clearRect(0, 0, this._inputFrame.width, this._inputFrame.height);\n\n    this._outputFrame.getContext('2d').clearRect(0, 0, this._outputFrame.width, this._outputFrame.height);\n\n    this._inputFrame = null;\n    this._outputFrame = null;\n\n    this._updateElementsMediaStreamTrack();\n\n    return this;\n  };\n\n  return VideoTrack;\n}(MediaTrack);\n\nVideoTrack.DIMENSIONS_CHANGED = 'dimensionsChanged';\n\nfunction dimensionsChanged(track, elem) {\n  return track.dimensions.width !== elem.videoWidth || track.dimensions.height !== elem.videoHeight;\n}\n/**\n * A {@link VideoTrack}'s width and height.\n * @typedef {object} VideoTrack.Dimensions\n * @property {?number} width - The {@link VideoTrack}'s width or null if the\n *   {@link VideoTrack} has not yet started\n * @property {?number} height - The {@link VideoTrack}'s height or null if the\n *   {@link VideoTrack} has not yet started\n */\n\n/**\n * A {@link VideoProcessor}, when added via {@link VideoTrack#addProcessor},\n * is used to process incoming video frames before\n * sending to the encoder or renderer.\n * @typedef {object} VideoProcessor\n * @property {function} processFrame - A callback to receive input and output frame buffers for processing.\n * The input frame buffer contains the original video frame which can be used for additional processing\n * such as applying filters to it. The output frame buffer is used to receive the processed video frame\n * before sending to the encoder or renderer.\n *\n * Any exception raised (either synchronously or asynchronously) in `processFrame` will result in the frame being dropped.\n * This callback has the following signature:<br/><br/>\n * <code>processFrame(</code><br/>\n * &nbsp;&nbsp;<code>inputFrameBuffer: OffscreenCanvas,</code><br/>\n * &nbsp;&nbsp;<code>outputFrameBuffer: HTMLCanvasElement</code><br/>\n * <code>): Promise&lt;void&gt; | void;</code>\n *\n * @example\n * class GrayScaleProcessor {\n *   constructor(percentage) {\n *     this.percentage = percentage;\n *   }\n *   processFrame(inputFrameBuffer, outputFrameBuffer) {\n *     const context = outputFrameBuffer.getContext('2d');\n *     context.filter = `grayscale(${this.percentage}%)`;\n *     context.drawImage(inputFrameBuffer, 0, 0, inputFrameBuffer.width, inputFrameBuffer.height);\n *   }\n * }\n */\n\n/**\n * The {@link VideoTrack}'s dimensions changed.\n * @param {VideoTrack} track - The {@link VideoTrack} whose dimensions changed\n * @event VideoTrack#dimensionsChanged\n */\n\n/**\n * The {@link VideoTrack} was disabled, i.e. \"paused\".\n * @param {VideoTrack} track - The {@link VideoTrack} that was disabled\n * @event VideoTrack#disabled\n */\n\n/**\n * The {@link VideoTrack} was enabled, i.e. \"unpaused\".\n * @param {VideoTrack} track - The {@link VideoTrack} that was enabled\n * @event VideoTrack#enabled\n */\n\n/**\n * The {@link VideoTrack} started. This means there is enough video data to\n * begin playback.\n * @param {VideoTrack} track - The {@link VideoTrack} that started\n * @event VideoTrack#started\n */\n\n\nmodule.exports = VideoTrack;","map":null,"metadata":{},"sourceType":"script"}